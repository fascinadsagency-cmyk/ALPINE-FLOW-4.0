#!/usr/bin/env python3
"""
ğŸ§¹ SCRIPT DE LIMPIEZA: De-duplicaciÃ³n de Tipos de ArtÃ­culo
==========================================================

Este script:
1. Identifica tipos de artÃ­culo duplicados (mismo label, diferentes values)
2. Selecciona un registro "maestro" para cada grupo de duplicados
3. Actualiza todos los artÃ­culos que apuntan a duplicados para que apunten al maestro
4. Elimina los registros duplicados sobrantes

âš ï¸  CRÃTICO: Este script modifica la base de datos. Hacer backup antes de ejecutar.
"""

import asyncio
from motor.motor_asyncio import AsyncIOMotorClient
from collections import defaultdict
import os
from datetime import datetime, timezone

# MongoDB connection
MONGO_URL = os.environ.get('MONGO_URL', 'mongodb://localhost:27017')
DB_NAME = os.environ.get('DB_NAME', 'alpineflow')

async def deduplicate_item_types():
    """De-duplicar tipos de artÃ­culo"""
    
    print("=" * 70)
    print("ğŸ§¹ INICIANDO LIMPIEZA DE TIPOS DE ARTÃCULO DUPLICADOS")
    print("=" * 70)
    print()
    
    # Connect to MongoDB
    client = AsyncIOMotorClient(MONGO_URL)
    db = client[DB_NAME]
    
    try:
        # PASO 1: Obtener todos los tipos de artÃ­culo
        print("ğŸ“Š PASO 1: Analizando tipos de artÃ­culo...")
        all_types = await db.item_types.find({}, {"_id": 0}).to_list(None)
        print(f"   Total tipos encontrados: {len(all_types)}")
        print()
        
        # PASO 2: Agrupar por label normalizado (case-insensitive, sin espacios)
        print("ğŸ” PASO 2: Identificando duplicados...")
        
        def normalize_for_comparison(text):
            """Normalizar texto para comparaciÃ³n (case-insensitive, sin espacios/guiones)"""
            return text.lower().strip().replace(" ", "").replace("_", "").replace("-", "")
        
        groups = defaultdict(list)
        for item_type in all_types:
            normalized_key = normalize_for_comparison(item_type['label'])
            groups[normalized_key].append(item_type)
        
        # Identificar grupos con duplicados
        duplicate_groups = {k: v for k, v in groups.items() if len(v) > 1}
        
        if not duplicate_groups:
            print("   âœ… No se encontraron duplicados. Base de datos limpia.")
            return
        
        print(f"   âŒ Encontrados {len(duplicate_groups)} grupos de duplicados:")
        print()
        
        total_merged = 0
        total_deleted = 0
        
        # PASO 3: Procesar cada grupo de duplicados
        for norm_label, duplicates in duplicate_groups.items():
            print(f"   ğŸ“¦ Grupo: {duplicates[0]['label']}")
            print(f"      Duplicados encontrados: {len(duplicates)}")
            
            # Seleccionar el registro maestro (el que tiene guion bajo, o el primero)
            master = None
            for dup in duplicates:
                if '_' in dup['value']:
                    master = dup
                    break
            if not master:
                master = duplicates[0]
            
            print(f"      âœ… Maestro seleccionado: '{master['value']}' (ID: {master['id']})")
            
            # Identificar duplicados a eliminar
            to_delete = [d for d in duplicates if d['id'] != master['id']]
            
            # PASO 4: Actualizar artÃ­culos que apuntan a duplicados
            for dup in to_delete:
                print(f"      ğŸ”„ Migrando artÃ­culos de '{dup['value']}' â†’ '{master['value']}'...")
                
                # Buscar artÃ­culos con este tipo
                items_with_dup = await db.items.count_documents({
                    "store_id": dup.get('store_id'),
                    "item_type": dup['value']
                })
                
                if items_with_dup > 0:
                    # Actualizar a maestro
                    result = await db.items.update_many(
                        {
                            "store_id": dup.get('store_id'),
                            "item_type": dup['value']
                        },
                        {
                            "$set": {
                                "item_type": master['value'],
                                "updated_at": datetime.now(timezone.utc).isoformat()
                            }
                        }
                    )
                    print(f"         âœ… {result.modified_count} artÃ­culos actualizados")
                    total_merged += result.modified_count
                else:
                    print(f"         â„¹ï¸  0 artÃ­culos (tipo sin uso)")
                
                # PASO 5: Eliminar tipo duplicado
                await db.item_types.delete_one({"id": dup['id']})
                print(f"         ğŸ—‘ï¸  Tipo '{dup['value']}' eliminado")
                total_deleted += 1
            
            print()
        
        # RESUMEN
        print("=" * 70)
        print("âœ… LIMPIEZA COMPLETADA")
        print("=" * 70)
        print(f"   ArtÃ­culos migrados: {total_merged}")
        print(f"   Tipos eliminados: {total_deleted}")
        print(f"   Grupos fusionados: {len(duplicate_groups)}")
        print()
        
    except Exception as e:
        print(f"âŒ ERROR: {e}")
        import traceback
        traceback.print_exc()
    finally:
        client.close()

async def create_unique_index():
    """Crear Ã­ndice Ãºnico para prevenir duplicados futuros"""
    
    print("=" * 70)
    print("ğŸ”’ CREANDO ÃNDICE ÃšNICO EN ITEM_TYPES")
    print("=" * 70)
    print()
    
    client = AsyncIOMotorClient(MONGO_URL)
    db = client[DB_NAME]
    
    try:
        # Crear Ã­ndice Ãºnico compuesto: store_id + value
        # Esto previene duplicados por tienda
        result = await db.item_types.create_index(
            [("store_id", 1), ("value", 1)],
            unique=True,
            name="unique_store_itemtype"
        )
        
        print(f"   âœ… Ãndice Ãºnico creado: {result}")
        print(f"   Campo: store_id + value")
        print(f"   Efecto: MongoDB rechazarÃ¡ duplicados automÃ¡ticamente")
        print()
        
    except Exception as e:
        if "duplicate key" in str(e).lower():
            print(f"   âš ï¸  Ya existe un Ã­ndice Ãºnico")
        else:
            print(f"   âŒ ERROR: {e}")
    finally:
        client.close()

async def main():
    """Ejecutar limpieza completa"""
    
    print()
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘  ğŸ§¹ LIMPIEZA DE INTEGRIDAD: TIPOS DE ARTÃCULO                     â•‘")
    print("â•‘                                                                    â•‘")
    print("â•‘  Este script eliminarÃ¡ duplicados y aplicarÃ¡ restricciones Ãºnicas â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()
    
    # Paso 1: Limpiar duplicados existentes
    await deduplicate_item_types()
    
    # Paso 2: Crear Ã­ndice Ãºnico
    await create_unique_index()
    
    print()
    print("âœ… PROCESO COMPLETADO")
    print()

if __name__ == "__main__":
    asyncio.run(main())
